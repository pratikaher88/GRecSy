{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "491d2468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31aac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratikaher/DGL/graph-rec/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting processing ml-1m ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratikaher/DGL/GRecSy/movielens_data_new.py:253: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  movie_info = pd.read_csv(file_path, sep='::', header=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......\n",
      "All rating edges : 1000209\n",
      "\tAll train rating edges : 900188\n",
      "\t\tTrain rating edges : 810169\n",
      "\t\tValid rating edges : 90019\n",
      "\tTest rating edges  : 100021\n",
      "Total user number = 6040, movie number = 3706\n",
      "Feature dim: \n",
      "user: torch.Size([6040, 23])\n",
      "movie: torch.Size([3706, 319])\n",
      "Train enc graph: \t#user:6040\t#movie:3706\t#pairs:810169\n",
      "Valid enc graph: \t#user:6040\t#movie:3706\t#pairs:90019\n",
      "Test enc graph: \t#user:6040\t#movie:3706\t#pairs:100021\n"
     ]
    }
   ],
   "source": [
    "from movielens_data_new import MovieLens\n",
    "import torch as th\n",
    "import numpy as np\n",
    "import dgl\n",
    "\n",
    "dataset = MovieLens(\"ml-1m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e1054924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>nearest_holiday</th>\n",
       "      <th>nearest_holiday_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 14:12:40</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 14:35:09</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 14:32:48</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 14:04:35</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-01-06 15:38:11</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-01-06</td>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating           timestamp  year  month        date  \\\n",
       "0        1      1193       5 2000-12-31 14:12:40  2000     12  2000-12-31   \n",
       "1        1       661       3 2000-12-31 14:35:09  2000     12  2000-12-31   \n",
       "2        1       914       3 2000-12-31 14:32:48  2000     12  2000-12-31   \n",
       "3        1      3408       4 2000-12-31 14:04:35  2000     12  2000-12-31   \n",
       "4        1      2355       5 2001-01-06 15:38:11  2001      1  2001-01-06   \n",
       "\n",
       "  nearest_holiday  nearest_holiday_days  \n",
       "0   Christmas Day                     6  \n",
       "1   Christmas Day                     6  \n",
       "2   Christmas Day                     6  \n",
       "3   Christmas Day                     6  \n",
       "4  New Year's Day                     5  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.all_rating_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f7174b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "535cab46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = dataset.all_rating_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c016da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating['timestamp'] = df_rating['timestamp'].apply(datetime.fromtimestamp)\n",
    "df_rating['year'] = df_rating['timestamp'].dt.year\n",
    "df_rating['month'] = df_rating['timestamp'].dt.month\n",
    "df_rating['date'] = df_rating['timestamp'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5224caa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 14:12:40</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 14:35:09</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 14:32:48</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 14:04:35</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-01-06 15:38:11</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>2000-04-25 19:35:41</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-04-25 16:21:27</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-04-25 16:19:06</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25 19:20:48</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25 19:19:29</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-04-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  movie_id  rating           timestamp  year  month  \\\n",
       "0              1      1193       5 2000-12-31 14:12:40  2000     12   \n",
       "1              1       661       3 2000-12-31 14:35:09  2000     12   \n",
       "2              1       914       3 2000-12-31 14:32:48  2000     12   \n",
       "3              1      3408       4 2000-12-31 14:04:35  2000     12   \n",
       "4              1      2355       5 2001-01-06 15:38:11  2001      1   \n",
       "...          ...       ...     ...                 ...   ...    ...   \n",
       "1000204     6040      1091       1 2000-04-25 19:35:41  2000      4   \n",
       "1000205     6040      1094       5 2000-04-25 16:21:27  2000      4   \n",
       "1000206     6040       562       5 2000-04-25 16:19:06  2000      4   \n",
       "1000207     6040      1096       4 2000-04-25 19:20:48  2000      4   \n",
       "1000208     6040      1097       4 2000-04-25 19:19:29  2000      4   \n",
       "\n",
       "               date  \n",
       "0        2000-12-31  \n",
       "1        2000-12-31  \n",
       "2        2000-12-31  \n",
       "3        2000-12-31  \n",
       "4        2001-01-06  \n",
       "...             ...  \n",
       "1000204  2000-04-25  \n",
       "1000205  2000-04-25  \n",
       "1000206  2000-04-25  \n",
       "1000207  2000-04-25  \n",
       "1000208  2000-04-25  \n",
       "\n",
       "[1000209 rows x 7 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f3ac734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holidays\n",
    "us_holidays = holidays.US()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08a2b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_map = {}\n",
    "L = []\n",
    "for (date, holiday_name) in holidays.US(years = 2000).items():\n",
    "    L.append((date, holiday_name))\n",
    "holiday_map[2000] = L[:]\n",
    "L = []\n",
    "for (date, holiday_name) in holidays.US(years = 2001).items():\n",
    "    L.append((date, holiday_name))\n",
    "holiday_map[2001] = L[:]\n",
    "L = []\n",
    "for (date, holiday_name) in holidays.US(years = 2002).items():\n",
    "    L.append((date, holiday_name))\n",
    "holiday_map[2002] = L[:]\n",
    "l = []\n",
    "for (date, holiday_name) in holidays.US(years = 2002).items():\n",
    "    L.append((date, holiday_name))\n",
    "holiday_map[2003] = L[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "29f42c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_holiday(year, current_date):\n",
    "    \n",
    "    holidays_that_year = holiday_map[year]\n",
    "    min_difference = float('inf')\n",
    "    closest_holiday = ''\n",
    "    \n",
    "    for (holiday_date, holiday_name) in holidays_that_year:\n",
    "        \n",
    "        current_difference = abs((current_date - holiday_date).days)\n",
    "        \n",
    "        if current_difference < min_difference:\n",
    "            \n",
    "            closest_holiday = holiday_name\n",
    "            min_difference = current_difference\n",
    "    \n",
    "    return closest_holiday\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc34b483",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_holiday_date(year, current_date):\n",
    "    \n",
    "    holidays_that_year = holiday_map[year]\n",
    "    min_difference = float('inf')\n",
    "    \n",
    "    for (holiday_date, holiday_name) in holidays_that_year:\n",
    "        \n",
    "        current_difference = abs((current_date - holiday_date).days)\n",
    "        min_difference = min(min_difference, current_difference)\n",
    "    \n",
    "    return min_difference\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "13bb4711",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating['nearest_holiday'] = df_rating.apply(lambda row : get_next_holiday(row['year'], row['date']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "76e955ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating['nearest_holiday_days'] = df_rating.apply(lambda row : get_next_holiday_date(row['year'], row['date']), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2455064b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>date</th>\n",
       "      <th>nearest_holiday</th>\n",
       "      <th>nearest_holiday_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>2000-12-31 14:12:40</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 14:35:09</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-12-31 14:32:48</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>2000-12-31 14:04:35</td>\n",
       "      <td>2000</td>\n",
       "      <td>12</td>\n",
       "      <td>2000-12-31</td>\n",
       "      <td>Christmas Day</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>2001-01-06 15:38:11</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2001-01-06</td>\n",
       "      <td>New Year's Day</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating           timestamp  year  month        date  \\\n",
       "0        1      1193       5 2000-12-31 14:12:40  2000     12  2000-12-31   \n",
       "1        1       661       3 2000-12-31 14:35:09  2000     12  2000-12-31   \n",
       "2        1       914       3 2000-12-31 14:32:48  2000     12  2000-12-31   \n",
       "3        1      3408       4 2000-12-31 14:04:35  2000     12  2000-12-31   \n",
       "4        1      2355       5 2001-01-06 15:38:11  2001      1  2001-01-06   \n",
       "\n",
       "  nearest_holiday  nearest_holiday_days  \n",
       "0   Christmas Day                     6  \n",
       "1   Christmas Day                     6  \n",
       "2   Christmas Day                     6  \n",
       "3   Christmas Day                     6  \n",
       "4  New Year's Day                     5  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43862844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.train_enc_graph.nodes['user'].data['features'] = dataset.user_feature\n",
    "# dataset.train_enc_graph.nodes['movie'].data['features'] = dataset.movie_feature\n",
    "\n",
    "# train_rating_info = th.FloatTensor(dataset.train_rating_info['rating'].values.astype(np.float32))\n",
    "# dataset.train_enc_graph.edges['rates'].data['rating'] =  train_rating_info\n",
    "# dataset.train_enc_graph.edges['rev-rates'].data['rating'] =  train_rating_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c61528c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.valid_enc_graph.nodes['user'].data['features'] = dataset.user_feature\n",
    "# dataset.valid_enc_graph.nodes['movie'].data['features'] = dataset.movie_feature\n",
    "\n",
    "# valid_rating_info = th.FloatTensor(dataset.valid_rating_info['rating'].values.astype(np.float32))\n",
    "# dataset.valid_enc_graph.edges['rates'].data['rating'] =  valid_rating_info\n",
    "# dataset.valid_enc_graph.edges['rev-rates'].data['rating'] =  valid_rating_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ae416ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.test_enc_graph.nodes['user'].data['features'] = dataset.user_feature\n",
    "# dataset.test_enc_graph.nodes['movie'].data['features'] = dataset.movie_feature\n",
    "\n",
    "# test_rating_info = th.FloatTensor(dataset.test_rating_info['rating'].values.astype(np.float32))\n",
    "# dataset.test_enc_graph.edges['rates'].data['rating'] =  test_rating_info\n",
    "# dataset.test_enc_graph.edges['rev-rates'].data['rating'] =  test_rating_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f064c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.train_enc_graph.edges['rates'].data['rating']\n",
    "# dataset.train_enc_graph.edges['rates']\n",
    "# dataset.train_enc_graph.edges(etype='rates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f205befc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeSpace(data={'features': tensor([[-0.2074,  0.0357, -0.3190,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.2781, -0.0447,  0.0315,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0071, -0.4135, -0.1930,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        ...,\n",
       "        [ 1.0057,  0.2101,  0.2003,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.1855, -0.0969, -0.1628,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.1218,  0.3169, -0.3073,  ...,  1.0000,  0.0000,  0.0000]])})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_enc_graph.nodes['movie'].data['node_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e85af38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dfdd060",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_enc_graph = dataset.train_enc_graph\n",
    "valid_enc_graph = dataset.valid_enc_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f538ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grecsy_hetero.model import MPNNConvModel\n",
    "\n",
    "params = {'hidden_dim' : 128, 'out_dim' : 64 }\n",
    "\n",
    "dim_dict = {'user': train_enc_graph.nodes['user'].data['features'].shape[1],\n",
    "            'movie': train_enc_graph.nodes['movie'].data['features'].shape[1],\n",
    "            'out': params['out_dim'],\n",
    "            'hidden': params['hidden_dim']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fbcd2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eids_dict = {}\n",
    "valid_eids_dict = {}\n",
    "\n",
    "eids = np.arange(train_enc_graph.number_of_edges(etype='rates'))\n",
    "eids = np.random.permutation(eids)\n",
    "\n",
    "test_size = int(len(eids) * 0.1)\n",
    "valid_size = int(len(eids) * 0.1)\n",
    "train_size = len(eids) - test_size - valid_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ca1adbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in train_enc_graph.etypes:\n",
    "    train_eids_dict[e] = eids[:train_size]\n",
    "    valid_eids_dict[e] = eids[train_size:train_size+valid_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abd5b0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pratikaher/DGL/graph-rec/venv/lib/python3.8/site-packages/dgl/dataloading/dataloader.py:968: DGLWarning: EdgeDataLoader directly taking a BlockSampler will be deprecated and it will not support feature prefetching. Please use dgl.dataloading.as_edge_prediction_sampler to wrap it.\n",
      "  dgl_warning(\n"
     ]
    }
   ],
   "source": [
    "sampler = dgl.dataloading.MultiLayerNeighborSampler([15, 10, 5])\n",
    "train_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "        train_enc_graph, train_eids_dict, \n",
    "        sampler, negative_sampler=dgl.dataloading.negative_sampler.Uniform(5), \n",
    "        shuffle=True, drop_last=False,\n",
    "        batch_size=16\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40a80936",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = dgl.dataloading.EdgeDataLoader(\n",
    "        valid_enc_graph, valid_eids_dict, \n",
    "        sampler, negative_sampler=dgl.dataloading.negative_sampler.Uniform(5), \n",
    "        shuffle=True, drop_last=False,\n",
    "        batch_size=16\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b361e454",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MPNNConvModel(train_enc_graph, dim_dict)\n",
    "optimizer = th.optim.Adam(model.parameters(), lr=0.0001,weight_decay=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f165f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grecsy_hetero.model import compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23805c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_single_epoch(valid_dataloader):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "\n",
    "        for _, pos_g, neg_g, blocks in valid_dataloader:\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            input_features = blocks[0].srcdata['features']\n",
    "\n",
    "            _, pos_score, neg_score = model(blocks,\n",
    "                                    input_features,\n",
    "                                    pos_g,\n",
    "                                    neg_g)\n",
    "\n",
    "            # print(pos_score, neg_score)\n",
    "            loss = compute_loss(pos_score, neg_score)\n",
    "            total_val_loss += loss.item()\n",
    "    \n",
    "    return total_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9e62cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_single_epoch(train_dataloader):\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    for _, pos_g, neg_g, blocks in train_dataloader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_features = blocks[0].srcdata['features']\n",
    "        \n",
    "        _, pos_score, neg_score = model(blocks,\n",
    "                                        input_features,\n",
    "                                        pos_g,\n",
    "                                        neg_g)\n",
    "        \n",
    "#         print(pos_score, neg_score)\n",
    "\n",
    "        loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db0c43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b434212b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 0) cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [92], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     training_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_single_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [16], line 18\u001b[0m, in \u001b[0;36mtrain_single_epoch\u001b[0;34m(train_dataloader)\u001b[0m\n\u001b[1;32m     11\u001b[0m         _, pos_score, neg_score \u001b[38;5;241m=\u001b[39m model(blocks,\n\u001b[1;32m     12\u001b[0m                                         input_features,\n\u001b[1;32m     13\u001b[0m                                         pos_g,\n\u001b[1;32m     14\u001b[0m                                         neg_g)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#         print(pos_score, neg_score)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#         optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     21\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/DGL/GRecSy/grecsy_hetero/model.py:26\u001b[0m, in \u001b[0;36mcompute_loss\u001b[0;34m(pos_score, neg_score)\u001b[0m\n\u001b[1;32m     21\u001b[0m pos_score_tensor, neg_score_tensor \u001b[38;5;241m=\u001b[39m pos_score_tensor\u001b[38;5;241m.\u001b[39msqueeze(), neg_score_tensor\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# print(\"INPUT TENSORS\",pos_score_tensor, neg_score_tensor)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# if pos_score_tensor.get_shape[1] > 0 and neg_score_tensor.get_shape[1] > 0:\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpos_score_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_score_tensor\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([torch\u001b[38;5;241m.\u001b[39mones(pos_score_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), torch\u001b[38;5;241m.\u001b[39mzeros(neg_score_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print(F.binary_cross_entropy_with_logits(scores, labels))\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 0) cannot be concatenated"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    \n",
    "    print(f\"Epoch {i}\")\n",
    "    \n",
    "    training_loss = train_single_epoch(train_dataloader)\n",
    "    \n",
    "    print(f\"Training Loss : {training_loss}\")\n",
    "    \n",
    "#     validation_loss = validation_single_epoch(valid_dataloader)\n",
    "    \n",
    "#     print(f\"Validation Loss : {validation_loss}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905fec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = th.empty([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfa5292",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = th.Tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11222439",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5bb8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = th.cat((a, b), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c036db",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a658b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
